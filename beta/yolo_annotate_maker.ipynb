{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from shutil import copyfile, rmtree\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from django.db.models import Q\n",
    "from django.contrib.auth.models import User\n",
    "\n",
    "from app.models import Label,Image,Batch, Comment, STATUS_CHOICES\n",
    "from app.models import TODO, TAGGING, REVIEWING, DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join('.', 'static', 'dataset')\n",
    "yolo_path = os.path.join('.', 'yolo')\n",
    "yolo_anno_dir = os.path.join(yolo_path, 'annotate')\n",
    "obj_path = os.path.join(yolo_anno_dir, 'obj')\n",
    "\n",
    "if os.path.exists(obj_path):\n",
    "    rmtree(obj_path)\n",
    "os.makedirs(obj_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "classcnt = 0\n",
    "classidx = dict()\n",
    "stop = ['/.', '.', './', '\\.', '\\.']\n",
    "\n",
    "def get_class(label):\n",
    "    global classidx, classcnt\n",
    "    info = [label.brand, label.model]\n",
    "    cls = \"{}.{}\".format(*info).lower().strip()\n",
    "    if not any(info) or cls in stop:\n",
    "        cls = \"unknown\"\n",
    "    if not cls in classidx:\n",
    "        classidx[cls] = classcnt\n",
    "        classcnt += 1\n",
    "    return cls\n",
    "\n",
    "def get_coord(label):\n",
    "    return label.x, label.y, label.width, label.height\n",
    "\n",
    "def get_yolo_anno(mat, label):\n",
    "    imh, imw = mat.shape[:2]\n",
    "    x, y, w, h = get_coord(label)\n",
    "    print(x, y, w, h)\n",
    "    cls = get_class(label)\n",
    "    dw = 1.0/imw\n",
    "    dh = 1.0/imh\n",
    "    x = (x+(x+w))/2.0\n",
    "    y = (y+(y+h))/2.0\n",
    "    x = x*dw\n",
    "    w = w*dw\n",
    "    y = y*dh\n",
    "    h = h*dh\n",
    "    \n",
    "#     x, y, w, h = get_coord(label)\n",
    "#     rx = (x+(w/2.0))/imw\n",
    "#     ry = (y+(h/2.0))/imh\n",
    "#     rw = w/2.0/imw\n",
    "#     rh = h/2.0/imh\n",
    "#     cls = get_class(label)\n",
    "    return classidx[cls], x, y, w, h\n",
    "\n",
    "def recheck_ratio(mat, labels, filename='test.png'):\n",
    "    imh, imw = mat.shape[:2]\n",
    "    print(imh)\n",
    "    tmp = mat.copy()\n",
    "    for label in labels:\n",
    "        cls, rx, ry, rw, rh = label\n",
    "        w = int(rw*imw)\n",
    "        h = int(rh*imh)\n",
    "        x1 = int(rx*imw-w/2.0)\n",
    "        y1 = int(ry*imh-h/2.0)\n",
    "        x2 = int(x1+w)\n",
    "        y2 = int(y1+h)\n",
    "        tmp = cv2.rectangle(tmp, (x1, y1), (x2, y2), (0, 255, 0))\n",
    "        w = int(rw*imw)\n",
    "        h = int(rh*imh)\n",
    "        x = int(rx*imw)\n",
    "        y = int(ry*imh)\n",
    "        tmp = cv2.circle(tmp, (x, y), h, (0,0,255))\n",
    "    cv2.imwrite(filename, tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 438, 500, 625)\n",
      "1080\n",
      "(1, 698, 604, 376)\n",
      "1080\n",
      "(416, 306, 253, 427)\n",
      "1080\n",
      "(2, 243, 1140, 830)\n",
      "1080\n",
      "(617, 277, 547, 399)\n",
      "1080\n"
     ]
    }
   ],
   "source": [
    "images = Image.objects.filter(batch__status=REVIEWING)\\\n",
    "    .exclude(label__isnull=True)\n",
    "    \n",
    "for i, image in enumerate(images):\n",
    "    labels = list()\n",
    "    labelled =  Label.objects.filter(image=image)\n",
    "    image_path = os.path.join(dataset_path, image.src_path)\n",
    "    fname, ext = os.path.splitext(image.src_path)\n",
    "    fname = image.id\n",
    "    obj_img_path = os.path.join(obj_path, \"{}.png\".format(fname))\n",
    "    obj_txt_path = os.path.join(obj_path, \"{}.txt\".format(fname))\n",
    "    mat = cv2.imread(image_path)\n",
    "    for label in labelled:\n",
    "        ret = get_yolo_anno(mat, label)\n",
    "        labels.append(ret)\n",
    "        \n",
    "#     !!!DEBUG\n",
    "#     recheck_ratio(mat, labels, \"./yolo/{}.png\".format(i))\n",
    "#     copyfile(image_path, obj_img_path)\n",
    "#     with open(obj_txt_path, 'w+') as fp:\n",
    "#         for label in labels:\n",
    "#             fp.write(\" \".join([str(x) for x in label]))\n",
    "#             fp.write(os.linesep)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namespath = os.path.join(yolo_anno_dir, 'obj.names')\n",
    "with open(namespath, 'w+') as fp:    \n",
    "    for k, v in sorted( classidx.items(), key=lambda x:x[1] ):\n",
    "        fp.write(k)\n",
    "        fp.write(os.linesep)\n",
    "\n",
    "datapath = os.path.join(yolo_anno_dir, 'obj.data')\n",
    "context = \"\"\"classes= {}\n",
    "train  = yolo/annotate/train.txt\n",
    "valid  = yolo/annotate/test.txt\n",
    "names = yolo/annotate/obj.names\n",
    "backup = backup/\"\"\".format(len(classidx))\n",
    "with open(datapath, 'w+') as fp:\n",
    "    fp.write(context)\n",
    "\n",
    "all_images = images.all().values_list('id')\n",
    "train, test = train_test_split(all_images, test_size=0.1)\n",
    "print len(train), len(test)\n",
    "with open(os.path.join(yolo_anno_dir, 'train.txt'), 'w+') as fp:\n",
    "    for x in train:\n",
    "        fname = \"{}.jpg\".format(x[0])\n",
    "        fp.write(os.path.join(obj_path, fname)+os.linesep)\n",
    "        \n",
    "with open(os.path.join(yolo_anno_dir, 'test.txt'), 'w+') as fp:\n",
    "    for x in test:\n",
    "        fname = \"{}.jpg\".format(x[0])\n",
    "        fp.write(os.path.join(obj_path, fname)+os.linesep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cfg(args) :\n",
    "    return \"\"\"[net]\n",
    "batch={}\n",
    "subdivisions={}\n",
    "width=608\n",
    "height=608\n",
    "channels=3\n",
    "momentum=0.9\n",
    "decay=0.0005\n",
    "angle=0\n",
    "saturation = 1.5\n",
    "exposure = 1.5\n",
    "hue=.1\n",
    "\n",
    "learning_rate=0.001\n",
    "burn_in=1000\n",
    "max_batches = 500200\n",
    "policy=steps\n",
    "steps=400000,450000\n",
    "scales=.1,.1\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=32\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[maxpool]\n",
    "size=2\n",
    "stride=2\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=64\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[maxpool]\n",
    "size=2\n",
    "stride=2\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=64\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[maxpool]\n",
    "size=2\n",
    "stride=2\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[maxpool]\n",
    "size=2\n",
    "stride=2\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[maxpool]\n",
    "size=2\n",
    "stride=2\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=1024\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=1024\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=1024\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "\n",
    "#######\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=1024\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=1024\n",
    "activation=leaky\n",
    "\n",
    "[route]\n",
    "layers=-9\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "filters=64\n",
    "activation=leaky\n",
    "\n",
    "[reorg]\n",
    "stride=2\n",
    "\n",
    "[route]\n",
    "layers=-1,-4\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=1024\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "filters={}\n",
    "activation=linear\n",
    "\n",
    "\n",
    "[region]\n",
    "anchors =  0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828\n",
    "bias_match=1\n",
    "classes={}\n",
    "coords=4\n",
    "num=5\n",
    "softmax=1\n",
    "jitter=.3\n",
    "rescore=1\n",
    "\n",
    "object_scale=5\n",
    "noobject_scale=1\n",
    "class_scale=1\n",
    "coord_scale=1\n",
    "\n",
    "absolute=1\n",
    "thresh = .6\n",
    "random=1\"\"\".format(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nclass = len(classidx)\n",
    "train_cfg = (64, 8, (nclass+5)*5, nclass)\n",
    "test_cfg = (1, 1, (nclass+5)*5, nclass)\n",
    "\n",
    "path = os.path.join(yolo_path, 'yolo-obj-train.cfg')\n",
    "with open(path, 'w+') as fp:\n",
    "    fp.write(create_cfg(train_cfg))\n",
    "\n",
    "path = os.path.join(yolo_path, 'yolo-obj-test.cfg')\n",
    "with open(path, 'w+') as fp:\n",
    "    fp.write(create_cfg(test_cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./darknet detector train yolo/annotate/obj.data cfg/yolo-obj.cfg darknet19_448.conv.23\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
